#!/usr/bin/env python3
"""
Project Cleanup Script - Remove Duplicate and Temporary Files
Ù…Ø³Ø­ Ø§Ù„Ù…Ù„ÙØ§Øª Ø§Ù„Ù…ÙƒØ±Ø±Ø© ÙˆØ§Ù„Ø²Ø§Ø¦Ø¯Ø© Ù…Ù† Ø§Ù„Ù…Ø´Ø±ÙˆØ¹
"""

import os
import shutil
import json
from pathlib import Path

def cleanup_project():
    """ØªÙ†Ø¸ÙŠÙ Ø§Ù„Ù…Ø´Ø±ÙˆØ¹ Ù…Ù† Ø§Ù„Ù…Ù„ÙØ§Øª Ø§Ù„Ù…ÙƒØ±Ø±Ø© ÙˆØ§Ù„Ø²Ø§Ø¦Ø¯Ø©"""
    
    base_path = Path("c:/Users/hp/Desktop/zeyad/workers-app")
    removed_files = []
    
    # Ù‚Ø§Ø¦Ù…Ø© Ø§Ù„Ù…Ù„ÙØ§Øª Ø§Ù„Ù…Ø¤Ù‚ØªØ© ÙˆØ§Ù„Ù…ÙƒØ±Ø±Ø© Ù„Ø­Ø°ÙÙ‡Ø§
    files_to_remove = [
        # Python Test Files - Ù…Ù„ÙØ§Øª Ø§Ù„Ø§Ø®ØªØ¨Ø§Ø± Ø§Ù„Ù…Ø¤Ù‚ØªØ©
        "check_users_database.py",
        "check_users_structure.py", 
        "comprehensive_frontend_fixer.py",
        "comprehensive_project_cleaner.py",
        "comprehensive_project_fixer.py",
        "comprehensive_test.py",
        "comprehensive_ui_fixer.py",
        "comprehensive_ui_test.py",
        "create_admin_user.py",
        "create_missing_tables.py",
        "detailed_frontend_analysis.py",
        "final_fix.py",
        "fix_frontend_issues.py",
        "fix_users_table.py",
        "fix_worker_documents_table.py",
        "frontend_critical_fixes.py",
        "frontend_fixes_test.py",
        "live_comprehensive_test.py",
        "meta_env_fixes_test.py",
        "project_cleaner.py",
        "project_status_report.py",
        "quick_fixes_test.py",
        "simple_api.py",
        "simple_test.py",
        "system_status_report.py",
        "test_login.py",
        "test_login_debug.py",
        "test_login_detailed.py",
        
        # Report Files - Ù…Ù„ÙØ§Øª Ø§Ù„ØªÙ‚Ø§Ø±ÙŠØ± Ø§Ù„Ù…Ø¤Ù‚ØªØ©
        "CLEANUP_SUMMARY.md",
        "COMPREHENSIVE_FIXES_REPORT.md",
        "FINAL_COMPLETION_REPORT_COMPREHENSIVE.md",
        "FINAL_COMPREHENSIVE_TESTING_REPORT.md",
        "FINAL_PROJECT_COMPLETION_REPORT.md",
        "FRONTEND_FIXES_SUMMARY.md",
        "META_ENV_FIXES_SUMMARY.md",
        "TESTING_COMPLETE_REPORT.md",
        
        # JSON Report Files - Ù…Ù„ÙØ§Øª Ø§Ù„ØªÙ‚Ø§Ø±ÙŠØ± JSON
        "COMPREHENSIVE_FIX_REPORT_20250710_155709.json",
        "DATABASE_USERS_REPORT_20250710_154140.json",
        "FRONTEND_FIXES_REPORT_20250710_152746.json",
        "META_ENV_FIXES_REPORT_20250710_153213.json",
        "PROJECT_CLEANUP_REPORT.json",
        "PROJECT_STATUS_REPORT_20250710_152039.json",
        
        # Log Files - Ù…Ù„ÙØ§Øª Ø§Ù„Ø³Ø¬Ù„
        "comprehensive_fix.log",
        "FINAL_SYSTEM_TEST_REPORT.txt",
        
        # HTML Test Files - Ù…Ù„ÙØ§Øª HTML Ø§Ù„Ø§Ø®ØªØ¨Ø§Ø±
        "test_connection.html",
        
        # Batch Files - Ù…Ù„ÙØ§Øª Ø§Ù„Ø¯ÙÙØ¹Ø§Øª
        "start.bat",
        "start.sh",
    ]
    
    # Ù…Ø¬Ù„Ø¯Ø§Øª Ù„Ù„Ø­Ø°Ù
    dirs_to_remove = [
        "backup_20250710_135732",
        "__pycache__",
        ".pytest_cache",
        "venv" if os.path.exists(base_path / "venv") and input("Ø­Ø°Ù Ù…Ø¬Ù„Ø¯ venvØŸ (y/n): ").lower() == 'y' else None
    ]
    
    # Frontend duplicate files - Ù…Ù„ÙØ§Øª Ø§Ù„ÙˆØ§Ø¬Ù‡Ø© Ø§Ù„Ù…ÙƒØ±Ø±Ø©
    frontend_files_to_remove = [
        "frontend/API_USAGE_GUIDE.md",
        "frontend/DASHBOARD_MIGRATION_GUIDE.md", 
        "frontend/FINAL_DECISION.md",
        "frontend/FRONTEND_REFACTORING.md",
        "frontend/TYPESCRIPT_ERROR_RESOLUTION.md",
    ]
    
    print("ğŸ§¹ Ø¨Ø¯Ø¡ ØªÙ†Ø¸ÙŠÙ Ø§Ù„Ù…Ø´Ø±ÙˆØ¹...")
    print("=" * 50)
    
    # Ø­Ø°Ù Ø§Ù„Ù…Ù„ÙØ§Øª
    for file_name in files_to_remove:
        file_path = base_path / file_name
        if file_path.exists():
            try:
                if file_path.is_file():
                    file_path.unlink()
                    removed_files.append(str(file_path))
                    print(f"âœ… ØªÙ… Ø­Ø°Ù: {file_name}")
                else:
                    print(f"âš ï¸ Ù„ÙŠØ³ Ù…Ù„Ù: {file_name}")
            except Exception as e:
                print(f"âŒ Ø®Ø·Ø£ ÙÙŠ Ø­Ø°Ù {file_name}: {e}")
    
    # Ø­Ø°Ù Ù…Ù„ÙØ§Øª Ø§Ù„ÙˆØ§Ø¬Ù‡Ø©
    for file_name in frontend_files_to_remove:
        file_path = base_path / file_name
        if file_path.exists():
            try:
                file_path.unlink()
                removed_files.append(str(file_path))
                print(f"âœ… ØªÙ… Ø­Ø°Ù: {file_name}")
            except Exception as e:
                print(f"âŒ Ø®Ø·Ø£ ÙÙŠ Ø­Ø°Ù {file_name}: {e}")
    
    # Ø­Ø°Ù Ø§Ù„Ù…Ø¬Ù„Ø¯Ø§Øª
    for dir_name in dirs_to_remove:
        if dir_name is None:
            continue
        dir_path = base_path / dir_name
        if dir_path.exists():
            try:
                shutil.rmtree(dir_path)
                removed_files.append(str(dir_path))
                print(f"âœ… ØªÙ… Ø­Ø°Ù Ø§Ù„Ù…Ø¬Ù„Ø¯: {dir_name}")
            except Exception as e:
                print(f"âŒ Ø®Ø·Ø£ ÙÙŠ Ø­Ø°Ù Ø§Ù„Ù…Ø¬Ù„Ø¯ {dir_name}: {e}")
    
    # Ø­Ø°Ù Ù…Ù„ÙØ§Øª __pycache__ Ù…Ù† Ø¬Ù…ÙŠØ¹ Ø§Ù„Ù…Ø¬Ù„Ø¯Ø§Øª
    for pycache_dir in base_path.rglob("__pycache__"):
        try:
            shutil.rmtree(pycache_dir)
            removed_files.append(str(pycache_dir))
            print(f"âœ… ØªÙ… Ø­Ø°Ù: {pycache_dir}")
        except Exception as e:
            print(f"âŒ Ø®Ø·Ø£ ÙÙŠ Ø­Ø°Ù {pycache_dir}: {e}")
    
    # Ø­Ø°Ù Ù…Ù„ÙØ§Øª .pyc
    for pyc_file in base_path.rglob("*.pyc"):
        try:
            pyc_file.unlink()
            removed_files.append(str(pyc_file))
            print(f"âœ… ØªÙ… Ø­Ø°Ù: {pyc_file}")
        except Exception as e:
            print(f"âŒ Ø®Ø·Ø£ ÙÙŠ Ø­Ø°Ù {pyc_file}: {e}")
    
    # Ø¥Ù†Ø´Ø§Ø¡ ØªÙ‚Ø±ÙŠØ± Ø§Ù„ØªÙ†Ø¸ÙŠÙ
    cleanup_report = {
        "cleanup_date": "2025-07-10",
        "total_files_removed": len(removed_files),
        "removed_files": removed_files,
        "summary": {
            "python_test_files": len([f for f in removed_files if f.endswith('.py')]),
            "report_files": len([f for f in removed_files if f.endswith(('.md', '.json', '.txt', '.log'))]),
            "cache_dirs": len([f for f in removed_files if '__pycache__' in f]),
            "backup_dirs": len([f for f in removed_files if 'backup' in f])
        }
    }
    
    with open(base_path / "cleanup_report.json", "w", encoding="utf-8") as f:
        json.dump(cleanup_report, f, indent=2, ensure_ascii=False)
    
    print("\n" + "=" * 50)
    print("ğŸ‰ ØªÙ… ØªÙ†Ø¸ÙŠÙ Ø§Ù„Ù…Ø´Ø±ÙˆØ¹ Ø¨Ù†Ø¬Ø§Ø­!")
    print(f"ğŸ“Š Ø¥Ø¬Ù…Ø§Ù„ÙŠ Ø§Ù„Ù…Ù„ÙØ§Øª Ø§Ù„Ù…Ø­Ø°ÙˆÙØ©: {len(removed_files)}")
    print(f"ğŸ Ù…Ù„ÙØ§Øª Python: {cleanup_report['summary']['python_test_files']}")
    print(f"ğŸ“‹ Ù…Ù„ÙØ§Øª Ø§Ù„ØªÙ‚Ø§Ø±ÙŠØ±: {cleanup_report['summary']['report_files']}")
    print(f"ğŸ—‚ï¸ Ù…Ø¬Ù„Ø¯Ø§Øª Ø§Ù„ØªØ®Ø²ÙŠÙ† Ø§Ù„Ù…Ø¤Ù‚Øª: {cleanup_report['summary']['cache_dirs']}")
    print(f"ğŸ’¾ Ù…Ø¬Ù„Ø¯Ø§Øª Ø§Ù„Ù†Ø³Ø® Ø§Ù„Ø§Ø­ØªÙŠØ§Ø·ÙŠ: {cleanup_report['summary']['backup_dirs']}")
    print(f"ğŸ“„ ØªÙ‚Ø±ÙŠØ± Ø§Ù„ØªÙ†Ø¸ÙŠÙ: cleanup_report.json")
    
    # Ø§Ù„Ù…Ù„ÙØ§Øª Ø§Ù„Ù…ØªØ¨Ù‚ÙŠØ© Ø§Ù„Ù…Ù‡Ù…Ø©
    print("\nğŸ“‚ Ø§Ù„Ù…Ù„ÙØ§Øª Ø§Ù„Ù…Ù‡Ù…Ø© Ø§Ù„Ù…ØªØ¨Ù‚ÙŠØ©:")
    important_files = [
        "README.md",
        "QUICK_START.md", 
        "SETUP_GUIDE.md",
        "requirements.txt",
        "alembic.ini",
        "workers.db"
    ]
    
    for file_name in important_files:
        file_path = base_path / file_name
        if file_path.exists():
            print(f"âœ… {file_name}")
        else:
            print(f"âš ï¸ {file_name} - ØºÙŠØ± Ù…ÙˆØ¬ÙˆØ¯")

if __name__ == "__main__":
    cleanup_project()
